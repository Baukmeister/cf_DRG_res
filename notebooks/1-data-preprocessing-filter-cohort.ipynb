{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle as pickle\n",
    "\n",
    "import pandas as pd\n",
    "import pandas.io.sql as sqlio\n",
    "import psycopg2\n",
    "import getpass\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up postgres connection\n",
    "conn = psycopg2.connect(\n",
    "    database=\"mimic\", \n",
    "    user='postgres',\n",
    "    password=getpass.getpass(\"Enter postgres password\"), \n",
    "    host=\"127.0.0.1\", \n",
    "    port=\"5432\",\n",
    "    options=f'-c search_path=mimiciii')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose between the disease type of ccnstructed data\n",
    "DISEASE_TYPE = 'CARDIOVASCULAR' # `CARDIOVASCULAR` or `SEPSIS` or `ARDS` (acute respiratory distress syndrome)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Identify all filtered patient ids, using first 3-digit category ICD-9 codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "lists of ICD 9 codes (related to heart diseases):\n",
    "\n",
    "393-398  Chronic Rheumatic Heart Disease\n",
    "410-414  Ischemic Heart Disease\n",
    "420-429  Other Forms Of Heart Disease\n",
    "\"\"\"\n",
    "\n",
    "heart_disease_query = \"\"\"\n",
    "    SELECT DISTINCT(subject_id)\n",
    "    FROM diagnoses_icd\n",
    "    WHERE (\n",
    "        icd9_code LIKE '393%' OR\n",
    "        icd9_code LIKE '394%' OR\n",
    "        icd9_code LIKE '395%' OR\n",
    "        icd9_code LIKE '396%' OR\n",
    "        icd9_code LIKE '397%' OR\n",
    "        icd9_code LIKE '398%' OR\n",
    "        icd9_code LIKE '410%' OR\n",
    "        icd9_code LIKE '411%' OR\n",
    "        icd9_code LIKE '412%' OR\n",
    "        icd9_code LIKE '413%' OR\n",
    "        icd9_code LIKE '414%' OR\n",
    "        icd9_code LIKE '420%' OR\n",
    "        icd9_code LIKE '421%' OR\n",
    "        icd9_code LIKE '422%' OR\n",
    "        icd9_code LIKE '423%' OR\n",
    "        icd9_code LIKE '424%' OR\n",
    "        icd9_code LIKE '425%' OR\n",
    "        icd9_code LIKE '426%' OR\n",
    "        icd9_code LIKE '427%' OR\n",
    "        icd9_code LIKE '428%' OR\n",
    "        icd9_code LIKE '429%' \n",
    "    );\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "lists of ICD 9 codes (related to sepsis diseases):\n",
    "\n",
    "038 - Septicaemia\n",
    "054.5 - Herpetic septicemia \n",
    "670.2 - Major puerperal infection : Puerperal sepsis (?) \n",
    "785.52 - Septic shock \n",
    "995.91 - Sepsis\n",
    "995.92 - Sepsis, with acute organ dysfunction/multiple organ dysfunction/severe\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "sepsis_query = \"\"\"\n",
    "    SELECT DISTINCT(subject_id)\n",
    "    FROM diagnoses_icd\n",
    "    WHERE (\n",
    "        icd9_code LIKE '038%' OR\n",
    "        icd9_code LIKE '0545%' OR\n",
    "        icd9_code LIKE '78552' OR\n",
    "        icd9_code LIKE '99591' OR\n",
    "        icd9_code LIKE '99592'\n",
    "    );\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "lists of ICD 9 codes (related to sepsis diseases):\n",
    "518.5 - ARDS \n",
    "518.81 - Respiratory failure, acute\n",
    "\"\"\"\n",
    "\n",
    "ards_query = \"\"\"\n",
    "    SELECT DISTINCT(subject_id)\n",
    "    FROM diagnoses_icd\n",
    "    WHERE (\n",
    "        icd9_code LIKE '5185%' OR\n",
    "        icd9_code LIKE '51881'\n",
    "    );\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all the patient ids with chosen disease\n",
    "if DISEASE_TYPE == 'CARDIOVASCULAR':\n",
    "    filter_query = heart_disease_query \n",
    "elif DISEASE_TYPE == 'SEPSIS':\n",
    "    filter_query = sepsis_query\n",
    "elif DISEASE_TYPE == 'ARDS':\n",
    "    filter_query = ards_query\n",
    "else:\n",
    "    print(\"Error. Not implemented.\")\n",
    "\n",
    "filtered_subject_ids = pd.read_sql(filter_query, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to a set for filtering\n",
    "subject_id_set = set(filtered_subject_ids['subject_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "24138"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(subject_id_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Retrieve all admission ids from last 12 months since each patient's last admission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the subtraction between all admission times and the last admission by each patient; in year unit\n",
    "admissions_diff = pd.read_sql(\n",
    "    \"\"\"\n",
    "    SELECT a.subject_id, a.hadm_id,\n",
    "    ROUND((cast(a.admittime as date)-cast(last_admission_time.max_admittime as date))/365.242,2) AS diff_from_last \n",
    "    FROM admissions AS a\n",
    "    LEFT JOIN\n",
    "        (SELECT subject_id,  MAX(admittime) AS max_admittime\n",
    "        FROM admissions\n",
    "        GROUP BY subject_id\n",
    "        ) AS last_admission_time\n",
    "    ON a.subject_id=last_admission_time.subject_id\n",
    "    WHERE a.subject_id IN %(subject_id_set)s;\n",
    "    \"\"\", \n",
    "    con=conn,\n",
    "    params={'subject_id_set': tuple(subject_id_set)}) # add 'WHERE' to filter paient ids in SQL query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(33872, 3)"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "admissions_diff.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "count    33872.000000\nmean        -0.536699\nstd          1.446672\nmin        -11.560000\n25%         -0.100000\n50%          0.000000\n75%          0.000000\nmax          0.000000\nName: diff_from_last, dtype: float64"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "admissions_diff['diff_from_last'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # uncomment to sanity check, using an id from `filtered_subject_ids`\n",
    "# # filtered_subject_ids.head()\n",
    "# admissions_diff[admissions_diff['subject_id']==36]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all the admissions from last 12 months since each patient's last admission ('diff_from_last' >= -1 <year>)\n",
    "admissions_last_year = admissions_diff[admissions_diff['diff_from_last'] >= -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # uncomment to sanity check\n",
    "# admissions_last_year[admissions_last_year['subject_id']==36]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all hadm_id's into a set\n",
    "hadm_id_set = set(admissions_last_year['hadm_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "29059"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(hadm_id_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Get all drug events and process them by remove 'stopword' events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all the drug events from table 'inputevents_mv'\n",
    "# update: add \"order by\" for correct ordered formats -> https://stackoverflow.com/questions/369362/postgresql-changing-returned-rows-order\n",
    "drug_events = pd.read_sql(\n",
    "    \"\"\"\n",
    "    SELECT im.subject_id, im.hadm_id, im.starttime, im.itemid, di.abbreviation\n",
    "    FROM inputevents_mv as im\n",
    "    JOIN d_items as di\n",
    "    ON im.itemid=di.itemid\n",
    "    WHERE im.subject_id IN %(subject_id_set)s\n",
    "    AND im.hadm_id IN %(hadm_id_set)s\n",
    "    ORDER BY im.subject_id ASC, \n",
    "            im.starttime ASC, \n",
    "            im.itemid ASC;;\n",
    "    \"\"\", \n",
    "    con=conn,\n",
    "    params={'subject_id_set': tuple(subject_id_set),\n",
    "           'hadm_id_set': tuple(hadm_id_set)}) # add 'WHERE' to filter paient and admission ids in SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(2325288, 5)"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drug_events.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "10790"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(drug_events['subject_id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # uncomment to sanity check\n",
    "# drug_events[drug_events['subject_id'] == 36]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Remove 'stopword' events (too frequent counts or too rare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count itemid values\n",
    "itemid_counts = drug_events['itemid'].value_counts()\n",
    "\n",
    "itemid_counts2 = itemid_counts.reset_index()\n",
    "itemid_counts2 = itemid_counts2.rename(columns={\"index\": \"itemid\", \"itemid\":\"counts\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# itemid_counts2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add 'proportion' of each itemid to the table \n",
    "itemid_counts2['proportion'] = itemid_counts2['counts']/sum(itemid_counts2['counts'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# itemid_counts2.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove these proportions that are larger than the `threshold` or the count is less than 5;\n",
    "# update: threshold for heart disease: 3.7% (0.037); for sepsis: 5.3% (0.053) ('PO-intake' not in the list); \n",
    "# each threshold was chosen by consultation with medical experts based on the frequency\n",
    "if DISEASE_TYPE == 'CARDIOVASCULAR':\n",
    "    prop_threshold = 0.037 \n",
    "elif DISEASE_TYPE == 'SEPSIS':\n",
    "    prop_threshold = 0.053\n",
    "elif DISEASE_TYPE == 'ARDS':\n",
    "    prop_threshold = 0.073\n",
    "else:\n",
    "    print(\"Error. Not implemented.\")\n",
    "\n",
    "itemid_counts3 = itemid_counts2[(itemid_counts2['proportion'] <= prop_threshold) & (itemid_counts2['counts'] >= 5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to a set - which contains item ids that are neither too frequent nor too rare\n",
    "itemid_set = set(itemid_counts3['itemid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(1372601, 5)"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drug_events_filtered2 = drug_events[drug_events['itemid'].isin(itemid_set)]\n",
    "\n",
    "drug_events_filtered2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # uncomment to sanity check\n",
    "# drug_events_filtered2[drug_events_filtered2['subject_id']==36]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Drop the duplicated items (which indicates different doses in the same session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Uncomment to view duplicated 'itemid's from the same session\n",
    "# drug_events_filtered.groupby(by='subject_id').apply(lambda x: x.sort_values('itemid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(1182305, 5)"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop the 'exact' duplicates (due to different doses) in the same input session\n",
    "drug_events_filtered3 = drug_events_filtered2.drop_duplicates()\n",
    "\n",
    "drug_events_filtered3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort by patient id and starttime (admission)\n",
    "drug_events_filtered3 = drug_events_filtered3.sort_values(['subject_id', 'starttime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove 'starttime', in order to drop duplicates from the same admission consecutively\n",
    "drug_events_filtered3 = drug_events_filtered3.drop(['starttime'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(1039380, 4)"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# also drop the duplicates in the same admission and next to each other (consecutively)\n",
    "drug_events_filtered4 = drug_events_filtered3.loc[(drug_events_filtered3.shift() != drug_events_filtered3).any(axis=1)]\n",
    "\n",
    "drug_events_filtered4.shape # the count of all drug events, after filtering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # sanity check\n",
    "# drug_events_filtered4[drug_events_filtered4['subject_id']==36]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\repos\\cf_DRG_res\\.venv\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# convert 'int' to 'str' for output\n",
    "drug_events_filtered4['itemid'] = drug_events_filtered4['itemid'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drug_events_filtered4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "10717"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drug_events_only = drug_events_filtered4.drop(['abbreviation'], axis=1)\n",
    "drug_events_only['event_type'] = 1 # Add 'event_type'=1 for sanity check when merging tables\n",
    "\n",
    "# drug_events_only.head()\n",
    "len(set(drug_events_only['subject_id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drug_events_only[drug_events_only['subject_id'] == 36] # sanity check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Get all the diagnosis codes by filtered admission ids (and then group by patient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_hadm_id_set = set(drug_events_only['hadm_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "diagnosis_codes = pd.read_sql(\n",
    "    sql=\"\"\"\n",
    "        SELECT di.*, a.admittime\n",
    "        FROM diagnoses_icd AS di\n",
    "        JOIN admissions AS a\n",
    "        ON di.hadm_id=a.hadm_id\n",
    "        WHERE di.hadm_id IN %(filtered_hadm_id_set)s;\n",
    "        \"\"\", \n",
    "    con=conn,\n",
    "    params={'filtered_hadm_id_set': tuple(filtered_hadm_id_set)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note: use the first 3 digits of the full icd 9 diagnosis codes, for the category\n",
    "diagnosis_codes['short_code'] = diagnosis_codes['icd9_code'].apply(lambda code: code[:3])\n",
    "\n",
    "# diagnosis_codes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_diagnosis_codes = diagnosis_codes.groupby(by=['subject_id']).apply(\n",
    "    lambda x: x.sort_values(['admittime', 'seq_num'], ascending=[True, True]))[['hadm_id', 'seq_num', 'short_code', 'admittime']]\n",
    "\n",
    "sorted_diagnosis_codes = sorted_diagnosis_codes.reset_index().drop('level_1', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # uncomment to sanity check \n",
    "# sorted_diagnosis_codes[sorted_diagnosis_codes['subject_id'] == 36]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Get all procedure codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "procedure_codes = pd.read_sql(\n",
    "    \"\"\"\n",
    "    SELECT a.admittime, procedures.* \n",
    "    FROM admissions AS a\n",
    "    RIGHT JOIN\n",
    "        (SELECT pi.subject_id, pi.hadm_id, pi.seq_num, pi.icd9_code, dip.short_title\n",
    "        FROM procedures_icd AS pi\n",
    "        JOIN d_icd_procedures AS dip\n",
    "        ON pi.icd9_code=dip.icd9_code) AS procedures\n",
    "    ON a.hadm_id=procedures.hadm_id\n",
    "    WHERE procedures.hadm_id IN %(filtered_hadm_id_set)s;\n",
    "    \"\"\", \n",
    "    con=conn,\n",
    "    params={'filtered_hadm_id_set': tuple(filtered_hadm_id_set)}) # add 'WHERE' to filter admission ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(53101, 6)"
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "procedure_codes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "9642"
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(procedure_codes['subject_id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # uncomment to sanity check\n",
    "# procedure_codes[procedure_codes['subject_id']==36]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(53101, 5)"
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "procedure_codes_filtered2 = procedure_codes.drop(['short_title'], axis=1)\n",
    "\n",
    "procedure_codes_filtered2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Group by subject_id and sort by admittime and seq_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group by subject_id and sort by admittime (first) and seq_num (second)\n",
    "procedure_codes_filtered3 = procedure_codes_filtered2.groupby(by='subject_id', sort=False).apply(\n",
    "    lambda x: x.sort_values(['admittime', 'seq_num']))\n",
    "\n",
    "# procedure_codes_filtered3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "procedure_codes_filtered4 = procedure_codes_filtered3.reset_index(level=[0,1], drop=True)\n",
    "\n",
    "# procedure_codes_filtered4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # sanity check\n",
    "# procedure_codes_filtered4[procedure_codes_filtered4['subject_id']==36]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Merge drug events and procedures, and then output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drug_events_only.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(53101, 7)"
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "procedure_codes_filtered4['event_type'] = 2\n",
    "procedure_codes_filtered4['itemid'] = procedure_codes_filtered4['icd9_code'] # rename the column name to merge the tables\n",
    "\n",
    "# procedure_codes_filtered4.head()\n",
    "procedure_codes_filtered4.shape # the count of all procedures, after filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = pd.concat([drug_events_only, procedure_codes_filtered4]).reset_index(level=0, drop=True)\n",
    "\n",
    "# merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(1039380, 7)"
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged[merged['event_type'] == 1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(53101, 7)"
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged[merged['event_type'] == 2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # sanity check to verify how many subjects are overlapped\n",
    "# overlapped_sbj = set(drug_events_only['subject_id']).intersection(set(procedure_codes_filtered4['subject_id']))\n",
    "\n",
    "# len(overlapped_sbj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sanity check\n",
    "# drug_events_only[drug_events_only['hadm_id'] == 183791]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sanity check\n",
    "# procedure_codes_filtered4[procedure_codes_filtered4['hadm_id'] == 183791]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note: df.groupby(by=['subject_id', 'hadm_id']) default sort=True... while `hadm_id` is randomly generated (no order with timestamp)\n",
    "merged_by_adm = merged.groupby(by=['subject_id', 'hadm_id'], sort=False)['itemid'].apply(list).reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged_by_adm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # sanity check\n",
    "# merged_by_adm[merged_by_adm['subject_id']==36]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the duplicated event/treatment next to each other (perhaps due to different timestamps after grouping)\n",
    "merged_by_adm['itemid'] = merged_by_adm['itemid'].apply(lambda x: [x[i] for i in range(len(x)) if (i==0) or x[i] != x[i-1]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_by_sbj = merged_by_adm.groupby(by='subject_id')['itemid'].apply(list).reset_index()\n",
    "\n",
    "# merged_by_sbj.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the count column for all the events\n",
    "merged_by_sbj['count'] = merged_by_sbj['itemid'].apply(lambda x: len([event for adm in x for event in adm]))\n",
    "\n",
    "# merged_by_sbj.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "count    10717.000000\nmean       101.805449\nstd        195.192724\nmin          1.000000\n25%         16.000000\n50%         41.000000\n75%         92.000000\nmax       3596.000000\nName: count, dtype: float64"
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_by_sbj['count'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "8059"
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filter/cut the event length to the event count threshold\n",
    "if DISEASE_TYPE == 'CARDIOVASCULAR':\n",
    "    event_count_threshold = 92 # 75% percentile \n",
    "elif DISEASE_TYPE == 'SEPSIS':\n",
    "    event_count_threshold = 92 # cut at 92 (~1400 samples); not 75% percentile, to reduce computational costs (len=281)\n",
    "elif DISEASE_TYPE == 'ARDS':\n",
    "    event_count_threshold = 92 # cut at 92 (~1782 samples); not 75% percentile, to reduce computational costs (len=319) (~3177 samples)\n",
    "\n",
    "filtered_events = merged_by_sbj[merged_by_sbj['count'] <= event_count_threshold]\n",
    "\n",
    "len(filtered_events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtered_events['itemid'].apply(lambda x: len(x)).hist() # check how many admission visits for each patient, after filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\repos\\cf_DRG_res\\.venv\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "# add 'Admission_in' and 'Admission_out' stamps in the grouped events\n",
    "filtered_events['final_seq'] = filtered_events['itemid'].apply(\n",
    "    lambda x: [\" \".join(adm) for adm in x]).apply(\n",
    "    lambda x: \"admin \" + \" admout admin \".join(x) + \" admout\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\repos\\cf_DRG_res\\.venv\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": "count    8059.000000\nmean       34.741903\nstd        24.284513\nmin         3.000000\n25%        14.000000\n50%        29.000000\n75%        52.000000\nmax       102.000000\nName: final_count, dtype: float64"
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_events['final_count'] = filtered_events['final_seq'].apply(lambda x: len(x.split()))\n",
    "\n",
    "# filtered_events.head()\n",
    "filtered_events['final_count'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # sanity check\n",
    "# filtered_events['final_count'].idxmax()\n",
    "# filtered_events.loc[282]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_subject_id_set = set(filtered_events['subject_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Update: Get the `final_subject_id_set` and then add the diagnosis columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_diagnosis_codes = sorted_diagnosis_codes[sorted_diagnosis_codes['subject_id'].isin(final_subject_id_set)]\n",
    "\n",
    "# filtered_diagnosis_codes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "8059"
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(filtered_diagnosis_codes['subject_id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filtered_diagnosis_codes2 = filtered_diagnosis_codes.groupby(by=['subject_id', 'hadm_id'], sort=False)['short_code'].apply(list).reset_index()\n",
    "\n",
    "# filtered_diagnosis_codes2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "diagnosis_by_sbj = filtered_diagnosis_codes2.groupby(by='subject_id')['short_code'].apply(list).reset_index()\n",
    "\n",
    "# diagnosis_by_sbj.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_diagnosis_codes3 = diagnosis_by_sbj.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add 'Admission_in' and 'Admission_out' stamps in the grouped events\n",
    "filtered_diagnosis_codes3['final_diag'] = diagnosis_by_sbj['short_code'].apply(\n",
    "    lambda x: [\" \".join(adm) for adm in x]).apply(\n",
    "    lambda x: \"admin \" + \" admout admin \".join(x) + \" admout\")\n",
    "\n",
    "# filtered_diagnosis_codes3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "146"
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_diagnosis_codes3['final_count_diag'] = filtered_diagnosis_codes3['final_diag'].apply(lambda x: len(x.split()))\n",
    "\n",
    "filtered_diagnosis_codes3['final_count_diag'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # sanity check\n",
    "# filtered_diagnosis_codes3[filtered_diagnosis_codes3['subject_id']==689]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Update: Get the `final_subject_id_set` and then find the drug/procedure coexistence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "## check the coexistance of drug event and procedures\n",
    "coexist_table = merged.groupby(by=['subject_id', 'hadm_id'], sort=False)['itemid'].apply(set).reset_index()\n",
    "\n",
    "# coexist_table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "coexist_table_filtered = coexist_table[coexist_table['subject_id'].isin(final_subject_id_set)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get rule-based dictionary of co-existing drugs/procedures\n",
    "coexist_dict = dict()\n",
    "\n",
    "for item_set in coexist_table_filtered['itemid']:\n",
    "    for item in item_set:\n",
    "        temp_dict = {item: item_set}\n",
    "        coexist_dict.update(temp_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export the event coexistence files\n",
    "for output_idx in [1, 2, 3, 4, 5]:\n",
    "    output_datapath = '../mimic_data_' + DISEASE_TYPE.lower() + str(output_idx) + '/'\n",
    "\n",
    "    os.makedirs(output_datapath, exist_ok=True)\n",
    "    with open(output_datapath + 'coexist_dict.pkl', 'wb') as f:\n",
    "        pickle.dump(coexist_dict, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Add survival flag (1: survival, 0: death)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# expire_flag: 1 indicates death in the hospital, and 0 indicates survival to hospital discharge.\n",
    "survival_subject_ids = pd.read_sql(\n",
    "    \"\"\"\n",
    "    SELECT subject_id FROM patients\n",
    "    WHERE expire_flag=0;\n",
    "    \"\"\", conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to a set of survival ids\n",
    "survival_id_set = set(survival_subject_ids['subject_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\repos\\cf_DRG_res\\.venv\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": "(8059, 6)"
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_events['survival'] = [1 if idx in survival_id_set else 0 for idx in filtered_events['subject_id']]\n",
    "\n",
    "filtered_events.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "1    5525\n0    2534\nName: survival, dtype: int64"
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_events['survival'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4 Export as the input format for DRG framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(8059, 4)"
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_diagnosis_codes3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(8059, 9)"
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_merged = filtered_events.merge(filtered_diagnosis_codes3, on='subject_id', how='inner')\n",
    "\n",
    "final_merged.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_merged['final_count_diag'] = final_merged['final_diag'].apply(lambda x: len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "count    8059.000000\nmean       18.434297\nstd        10.406458\nmin         3.000000\n25%        12.000000\n50%        16.000000\n75%        22.000000\nmax       146.000000\nName: final_count_diag, dtype: float64"
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_merged['final_count_diag'].describe() # max: 166 (updated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # update: check if there is some patient with different admission in diagnosis codes and drug events, should be no false\n",
    "# compared = final_merged['itemid'].apply(len) == final_merged['short_code'].apply(len)\n",
    "\n",
    "# compared[compared==False] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # sanity check \n",
    "# final_merged[final_merged['subject_id'] == 689]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into positive/negative data\n",
    "neg_data = final_merged[final_merged['survival'] == 0]['final_seq']\n",
    "pos_data = final_merged[final_merged['survival'] == 1]['final_seq']\n",
    "\n",
    "# update: diagnosis code split-ups\n",
    "neg_diag = final_merged[final_merged['survival'] == 0]['final_diag']\n",
    "pos_diag = final_merged[final_merged['survival'] == 1]['final_diag']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Export negative samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DISEASE_TYPE == 'CARDIOVASCULAR':\n",
    "    val_data_size = 200\n",
    "elif DISEASE_TYPE == 'SEPSIS' or DISEASE_TYPE == 'ARDS':\n",
    "    val_data_size = 100\n",
    "else:\n",
    "    print(\"Error. Not implemented.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train/validation; 200 validation samples and the rest are train\n",
    "validation_neg = neg_data.sample(n=val_data_size, random_state=3)\n",
    "train_neg = neg_data.drop(validation_neg.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write as txt files into '../mimic_data/'\n",
    "train_neg.to_csv(path_or_buf=output_datapath+'train_neg.txt', index=False, header=False, sep=' ', quoting=csv.QUOTE_NONE, escapechar=' ')\n",
    "validation_neg.to_csv(path_or_buf=output_datapath+'validation_neg.txt', index=False, header=False, sep=' ', quoting=csv.QUOTE_NONE, escapechar=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write as txt files into '../mimic_data/', update: DIAGNOSIS CODES\n",
    "neg_diag.loc[train_neg.index].to_csv(path_or_buf=output_datapath+'train_neg_diag.txt', index=False, header=False, sep=' ', quoting=csv.QUOTE_NONE, escapechar=' ')\n",
    "neg_diag.loc[validation_neg.index].to_csv(path_or_buf=output_datapath+'validation_neg_diag.txt', index=False, header=False, sep=' ', quoting=csv.QUOTE_NONE, escapechar=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Export positive samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train/validation; 200 validation samples and the rest are train\n",
    "validation_pos = pos_data.sample(n=val_data_size, random_state=3)\n",
    "train_pos = pos_data.drop(validation_pos.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write as txt files into '../mimic_data/'\n",
    "train_pos.to_csv(path_or_buf=output_datapath+'train_pos.txt', index=False, header=False, sep=' ', quoting=csv.QUOTE_NONE, escapechar=' ')\n",
    "validation_pos.to_csv(path_or_buf=output_datapath+'validation_pos.txt', index=False, header=False, sep=' ', quoting=csv.QUOTE_NONE, escapechar=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write as txt files into '../mimic_data/', update: DIAGNOSIS CODES\n",
    "pos_diag.loc[train_pos.index].to_csv(path_or_buf=output_datapath+'train_pos_diag.txt', index=False, header=False, sep=' ', quoting=csv.QUOTE_NONE, escapechar=' ')\n",
    "pos_diag.loc[validation_pos.index].to_csv(path_or_buf=output_datapath+'validation_pos_diag.txt', index=False, header=False, sep=' ', quoting=csv.QUOTE_NONE, escapechar=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5 Export samples in 5 random train/test splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use a for loop to creat 5 different train-test splits\n",
    "RANDOM_SEEDS = [3, 6, 9, 12, 15]\n",
    "\n",
    "output_idx = 1\n",
    "\n",
    "if not os.path.exists(\"../full_experiments1\"):\n",
    "    os.mkdir(\"../full_experiments1\")\n",
    "for seed in RANDOM_SEEDS:\n",
    "    output_datapath = '../full_experiments1/mimic_data_' + DISEASE_TYPE.lower() + str(output_idx) + '/'\n",
    "    \n",
    "    os.makedirs(output_datapath, exist_ok=True)\n",
    "\n",
    "    # Split into train/validation; 200 validation samples and the rest are train\n",
    "    validation_neg = neg_data.sample(n=val_data_size, random_state=seed)\n",
    "    train_neg = neg_data.drop(validation_neg.index)\n",
    "\n",
    "    # Write as txt files into '../mimic_data/'\n",
    "    train_neg.to_csv(path_or_buf=output_datapath+'train_neg.txt', index=False, header=False, sep=' ', quoting=csv.QUOTE_NONE, escapechar=' ')\n",
    "    validation_neg.to_csv(path_or_buf=output_datapath+'validation_neg.txt', index=False, header=False, sep=' ', quoting=csv.QUOTE_NONE, escapechar=' ')\n",
    "\n",
    "    # Write as txt files into '../mimic_data/', update: DIAGNOSIS CODES\n",
    "    neg_diag.loc[train_neg.index].to_csv(path_or_buf=output_datapath+'train_neg_diag.txt', index=False, header=False, sep=' ', quoting=csv.QUOTE_NONE, escapechar=' ')\n",
    "    neg_diag.loc[validation_neg.index].to_csv(path_or_buf=output_datapath+'validation_neg_diag.txt', index=False, header=False, sep=' ', quoting=csv.QUOTE_NONE, escapechar=' ')\n",
    "\n",
    "    # Split into train/validation; 200 validation samples and the rest are train\n",
    "    validation_pos = pos_data.sample(n=val_data_size, random_state=seed)\n",
    "    train_pos = pos_data.drop(validation_pos.index)\n",
    "\n",
    "    # Write as txt files into '../mimic_data/'\n",
    "    train_pos.to_csv(path_or_buf=output_datapath+'train_poms.txt', index=False, header=False, sep=' ', quoting=csv.QUOTE_NONE, escapechar=' ')\n",
    "    validation_pos.to_csv(path_or_buf=output_datapath+'validation_pos.txt', index=False, header=False, sep=' ', quoting=csv.QUOTE_NONE, escapechar=' ')\n",
    "\n",
    "    # Write as txt files into '../mimic_data/', update: DIAGNOSIS CODES\n",
    "    pos_diag.loc[train_pos.index].to_csv(path_or_buf=output_datapath+'train_pos_diag.txt', index=False, header=False, sep=' ', quoting=csv.QUOTE_NONE, escapechar=' ')\n",
    "    pos_diag.loc[validation_pos.index].to_csv(path_or_buf=output_datapath+'validation_pos_diag.txt', index=False, header=False, sep=' ', quoting=csv.QUOTE_NONE, escapechar=' ')\n",
    "    \n",
    "    output_idx += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}