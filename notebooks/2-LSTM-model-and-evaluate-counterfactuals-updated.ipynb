{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.neighbors import NearestNeighbors, LocalOutlierFactor\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "import random as python_random\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import editdistance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.compat.v1.Session(config=config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define MIMIC data path\n",
    "data_path = '../full_experiments1/mimic_data_cardiovascular1/' # mimic_data_sepsis or mimic_data_cardiovascular or mimic_data_ards\n",
    "\n",
    "# Load training data\n",
    "train_pos = pd.read_csv(data_path+'train_pos.txt', header=None)\n",
    "train_neg = pd.read_csv(data_path+'train_neg.txt', header=None)\n",
    "\n",
    "# Add target class label\n",
    "train_pos['survival'] = [1 for i in range(train_pos.shape[0])]\n",
    "train_neg['survival'] = [0 for i in range(train_neg.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concat into one data frame; and reorder it\n",
    "train = pd.concat([train_pos, train_neg]).reset_index()\n",
    "train_reordered = train.sample(frac=1, random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = train_reordered[0], train_reordered['survival']\n",
    "\n",
    "# X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load validation data\n",
    "validation_pos = pd.read_csv(data_path+'validation_pos.txt', header=None)\n",
    "validation_neg = pd.read_csv(data_path+'validation_neg.txt', header=None)\n",
    "\n",
    "# Add target class\n",
    "validation_pos['survival'] = [1 for i in range(validation_pos.shape[0])]\n",
    "validation_neg['survival'] = [0 for i in range(validation_neg.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation = pd.concat([validation_pos, validation_neg]).reset_index()\n",
    "validation_reordered = validation.sample(frac=1, random_state=3)\n",
    "\n",
    "# validation_reordered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val, y_val = validation_reordered[0], validation_reordered['survival']\n",
    "\n",
    "# X_val.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing\n",
    "\n",
    "#### 1.1 Conver all the events into sequence (token) ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the vocab size and max sequence lenght\n",
    "vocab_size = 1400 #(max vocab id~=1300 in the training data; ~670 for sepsis)\n",
    "max_seq_length = 104 #(the maximum sequence length in training/testing data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a text tokenizer to convert events\n",
    "tokenizer = Tokenizer(num_words = vocab_size)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "X_train_sequences = tokenizer.texts_to_sequences(X_train)\n",
    "X_val_sequences = tokenizer.texts_to_sequences(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Before texts_to_sequences()\n",
    "# print(f'Before texts_to_sequences():\\n {X_train.iloc[1]}\\n')\n",
    "\n",
    "# # After texts_to_sequences()\n",
    "# print(f'After texts_to_sequences():\\n {X_train_sequences[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Padding converted sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad X_train_sequences and X_val_sequences\n",
    "X_train_padded = sequence.pad_sequences(X_train_sequences, maxlen=max_seq_length, padding='post')\n",
    "X_val_padded = sequence.pad_sequences(X_val_sequences, maxlen=max_seq_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(7659, 104)"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_padded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(400, 104)"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val_padded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([  8,  43,  10,  17,   3,   2,  53, 147,  67, 154,  42, 228,   9,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0])"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val_padded[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Train the main LSTM model for survival prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For plotting the accuracy/loss of keras models\n",
    "def plot_graphs(history, string):\n",
    "    plt.plot(history.history[string])\n",
    "    plt.plot(history.history['val_'+string])\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(string)\n",
    "    plt.legend([string, 'val_'+string])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\floba\\AppData\\Local\\Temp\\ipykernel_18052\\2833775127.py:19: The name tf.keras.backend.set_session is deprecated. Please use tf.compat.v1.keras.backend.set_session instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Fix the random seeds to get consistent models\n",
    "## ref: https://keras.io/getting_started/faq/#how-can-i-obtain-reproducible-results-using-keras-during-development\n",
    "seed_value = 3\n",
    "\n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "\n",
    "# The below is necessary for starting Numpy generated random numbers in a well-defined initial state.\n",
    "np.random.seed(seed_value)\n",
    "\n",
    "# The below is necessary for starting core Python generated random numbers in a well-defined state.\n",
    "python_random.seed(seed_value)\n",
    "\n",
    "# The below set_seed() will make random number generation\n",
    "tf.random.set_seed(seed_value)\n",
    "\n",
    "# configure a new global `tensorflow` session\n",
    "session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
    "tf.compat.v1.keras.backend.set_session(sess)\n",
    "\n",
    "def reset_seeds(seed_value=3):\n",
    "    os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "    np.random.seed(seed_value) \n",
    "    python_random.seed(seed_value)\n",
    "    tf.random.set_seed(seed_value)\n",
    "\n",
    "reset_seeds() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the early stopping criteria\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', patience=3, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, None)]            0         \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, None, 128)         179200    \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, None, 128)        98816     \n",
      " l)                                                              \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirectio  (None, 128)              98816     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 376,961\n",
      "Trainable params: 376,961\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model structure\n",
    "# Input for variable-length sequences of integers\n",
    "inputs = keras.Input(shape=(None,), dtype=\"int32\")\n",
    "\n",
    "# Embed each integer in a 128-dimensional vector\n",
    "x = layers.Embedding(vocab_size, 128)(inputs)\n",
    "\n",
    "# Add 2 bidirectional LSTMs\n",
    "x = layers.Bidirectional(layers.LSTM(64, return_sequences=True))(x)\n",
    "x = layers.Bidirectional(layers.LSTM(64))(x)\n",
    "\n",
    "# Add a classifier\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "main_model = keras.Model(inputs, outputs)\n",
    "\n",
    "main_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "ename": "UnimplementedError",
     "evalue": "Graph execution error:\n\nDetected at node 'Adam/Adam/update/UnsortedSegmentSum' defined at (most recent call last):\n    File \"C:\\Users\\floba\\AppData\\Local\\Programs\\Python\\Python37\\lib\\runpy.py\", line 193, in _run_module_as_main\n      \"__main__\", mod_spec)\n    File \"C:\\Users\\floba\\AppData\\Local\\Programs\\Python\\Python37\\lib\\runpy.py\", line 85, in _run_code\n      exec(code, run_globals)\n    File \"C:\\repos\\cf_DRG_res\\.venv\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"C:\\repos\\cf_DRG_res\\.venv\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n      app.start()\n    File \"C:\\repos\\cf_DRG_res\\.venv\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 677, in start\n      self.io_loop.start()\n    File \"C:\\repos\\cf_DRG_res\\.venv\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Users\\floba\\AppData\\Local\\Programs\\Python\\Python37\\lib\\asyncio\\base_events.py\", line 541, in run_forever\n      self._run_once()\n    File \"C:\\Users\\floba\\AppData\\Local\\Programs\\Python\\Python37\\lib\\asyncio\\base_events.py\", line 1786, in _run_once\n      handle._run()\n    File \"C:\\Users\\floba\\AppData\\Local\\Programs\\Python\\Python37\\lib\\asyncio\\events.py\", line 88, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\repos\\cf_DRG_res\\.venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 471, in dispatch_queue\n      await self.process_one()\n    File \"C:\\repos\\cf_DRG_res\\.venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 460, in process_one\n      await dispatch(*args)\n    File \"C:\\repos\\cf_DRG_res\\.venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 367, in dispatch_shell\n      await result\n    File \"C:\\repos\\cf_DRG_res\\.venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 662, in execute_request\n      reply_content = await reply_content\n    File \"C:\\repos\\cf_DRG_res\\.venv\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 360, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"C:\\repos\\cf_DRG_res\\.venv\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 532, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\repos\\cf_DRG_res\\.venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2915, in run_cell\n      raw_cell, store_history, silent, shell_futures)\n    File \"C:\\repos\\cf_DRG_res\\.venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2960, in _run_cell\n      return runner(coro)\n    File \"C:\\repos\\cf_DRG_res\\.venv\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 78, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\repos\\cf_DRG_res\\.venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3186, in run_cell_async\n      interactivity=interactivity, compiler=compiler, result=result)\n    File \"C:\\repos\\cf_DRG_res\\.venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3377, in run_ast_nodes\n      if (await self.run_code(code, result,  async_=asy)):\n    File \"C:\\repos\\cf_DRG_res\\.venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3457, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\floba\\AppData\\Local\\Temp\\ipykernel_18052\\3197040789.py\", line 10, in <module>\n      callbacks=[early_stopping])\n    File \"C:\\repos\\cf_DRG_res\\.venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\repos\\cf_DRG_res\\.venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1384, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"C:\\repos\\cf_DRG_res\\.venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1021, in train_function\n      return step_function(self, iterator)\n    File \"C:\\repos\\cf_DRG_res\\.venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1010, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\repos\\cf_DRG_res\\.venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1000, in run_step\n      outputs = model.train_step(data)\n    File \"C:\\repos\\cf_DRG_res\\.venv\\lib\\site-packages\\keras\\engine\\training.py\", line 863, in train_step\n      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"C:\\repos\\cf_DRG_res\\.venv\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py\", line 532, in minimize\n      return self.apply_gradients(grads_and_vars, name=name)\n    File \"C:\\repos\\cf_DRG_res\\.venv\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py\", line 675, in apply_gradients\n      name=name)\n    File \"C:\\repos\\cf_DRG_res\\.venv\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py\", line 717, in _distributed_apply\n      var, apply_grad_to_update_var, args=(grad,), group=False)\n    File \"C:\\repos\\cf_DRG_res\\.venv\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py\", line 695, in apply_grad_to_update_var\n      grad.values, var, grad.indices, **apply_kwargs)\n    File \"C:\\repos\\cf_DRG_res\\.venv\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py\", line 1279, in _resource_apply_sparse_duplicate_indices\n      values=grad, indices=indices)\n    File \"C:\\repos\\cf_DRG_res\\.venv\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py\", line 61, in _deduplicate_indexed_slices\n      tf.shape(unique_indices)[0])\nNode: 'Adam/Adam/update/UnsortedSegmentSum'\nDeterministic GPU implementation of unsorted segment reduction op not available.\n\t [[{{node Adam/Adam/update/UnsortedSegmentSum}}]] [Op:__inference_train_function_10605]",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mUnimplementedError\u001B[0m                        Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_18052\\3197040789.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      8\u001B[0m     \u001B[0mbatch_size\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m64\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      9\u001B[0m     \u001B[0mvalidation_data\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX_val_padded\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_val\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 10\u001B[1;33m     callbacks=[early_stopping])\n\u001B[0m",
      "\u001B[1;32mC:\\repos\\cf_DRG_res\\.venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001B[0m in \u001B[0;36merror_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     65\u001B[0m     \u001B[1;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m  \u001B[1;31m# pylint: disable=broad-except\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     66\u001B[0m       \u001B[0mfiltered_tb\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_process_traceback_frames\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0me\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__traceback__\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 67\u001B[1;33m       \u001B[1;32mraise\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mwith_traceback\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfiltered_tb\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     68\u001B[0m     \u001B[1;32mfinally\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     69\u001B[0m       \u001B[1;32mdel\u001B[0m \u001B[0mfiltered_tb\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\repos\\cf_DRG_res\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001B[0m in \u001B[0;36mquick_execute\u001B[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[0;32m     53\u001B[0m     \u001B[0mctx\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mensure_initialized\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     54\u001B[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001B[1;32m---> 55\u001B[1;33m                                         inputs, attrs, num_outputs)\n\u001B[0m\u001B[0;32m     56\u001B[0m   \u001B[1;32mexcept\u001B[0m \u001B[0mcore\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_NotOkStatusException\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     57\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mname\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mUnimplementedError\u001B[0m: Graph execution error:\n\nDetected at node 'Adam/Adam/update/UnsortedSegmentSum' defined at (most recent call last):\n    File \"C:\\Users\\floba\\AppData\\Local\\Programs\\Python\\Python37\\lib\\runpy.py\", line 193, in _run_module_as_main\n      \"__main__\", mod_spec)\n    File \"C:\\Users\\floba\\AppData\\Local\\Programs\\Python\\Python37\\lib\\runpy.py\", line 85, in _run_code\n      exec(code, run_globals)\n    File \"C:\\repos\\cf_DRG_res\\.venv\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"C:\\repos\\cf_DRG_res\\.venv\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n      app.start()\n    File \"C:\\repos\\cf_DRG_res\\.venv\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 677, in start\n      self.io_loop.start()\n    File \"C:\\repos\\cf_DRG_res\\.venv\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Users\\floba\\AppData\\Local\\Programs\\Python\\Python37\\lib\\asyncio\\base_events.py\", line 541, in run_forever\n      self._run_once()\n    File \"C:\\Users\\floba\\AppData\\Local\\Programs\\Python\\Python37\\lib\\asyncio\\base_events.py\", line 1786, in _run_once\n      handle._run()\n    File \"C:\\Users\\floba\\AppData\\Local\\Programs\\Python\\Python37\\lib\\asyncio\\events.py\", line 88, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\repos\\cf_DRG_res\\.venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 471, in dispatch_queue\n      await self.process_one()\n    File \"C:\\repos\\cf_DRG_res\\.venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 460, in process_one\n      await dispatch(*args)\n    File \"C:\\repos\\cf_DRG_res\\.venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 367, in dispatch_shell\n      await result\n    File \"C:\\repos\\cf_DRG_res\\.venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 662, in execute_request\n      reply_content = await reply_content\n    File \"C:\\repos\\cf_DRG_res\\.venv\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 360, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"C:\\repos\\cf_DRG_res\\.venv\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 532, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\repos\\cf_DRG_res\\.venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2915, in run_cell\n      raw_cell, store_history, silent, shell_futures)\n    File \"C:\\repos\\cf_DRG_res\\.venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2960, in _run_cell\n      return runner(coro)\n    File \"C:\\repos\\cf_DRG_res\\.venv\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 78, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\repos\\cf_DRG_res\\.venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3186, in run_cell_async\n      interactivity=interactivity, compiler=compiler, result=result)\n    File \"C:\\repos\\cf_DRG_res\\.venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3377, in run_ast_nodes\n      if (await self.run_code(code, result,  async_=asy)):\n    File \"C:\\repos\\cf_DRG_res\\.venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3457, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\floba\\AppData\\Local\\Temp\\ipykernel_18052\\3197040789.py\", line 10, in <module>\n      callbacks=[early_stopping])\n    File \"C:\\repos\\cf_DRG_res\\.venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\repos\\cf_DRG_res\\.venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1384, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"C:\\repos\\cf_DRG_res\\.venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1021, in train_function\n      return step_function(self, iterator)\n    File \"C:\\repos\\cf_DRG_res\\.venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1010, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\repos\\cf_DRG_res\\.venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1000, in run_step\n      outputs = model.train_step(data)\n    File \"C:\\repos\\cf_DRG_res\\.venv\\lib\\site-packages\\keras\\engine\\training.py\", line 863, in train_step\n      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"C:\\repos\\cf_DRG_res\\.venv\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py\", line 532, in minimize\n      return self.apply_gradients(grads_and_vars, name=name)\n    File \"C:\\repos\\cf_DRG_res\\.venv\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py\", line 675, in apply_gradients\n      name=name)\n    File \"C:\\repos\\cf_DRG_res\\.venv\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py\", line 717, in _distributed_apply\n      var, apply_grad_to_update_var, args=(grad,), group=False)\n    File \"C:\\repos\\cf_DRG_res\\.venv\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py\", line 695, in apply_grad_to_update_var\n      grad.values, var, grad.indices, **apply_kwargs)\n    File \"C:\\repos\\cf_DRG_res\\.venv\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py\", line 1279, in _resource_apply_sparse_duplicate_indices\n      values=grad, indices=indices)\n    File \"C:\\repos\\cf_DRG_res\\.venv\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py\", line 61, in _deduplicate_indexed_slices\n      tf.shape(unique_indices)[0])\nNode: 'Adam/Adam/update/UnsortedSegmentSum'\nDeterministic GPU implementation of unsorted segment reduction op not available.\n\t [[{{node Adam/Adam/update/UnsortedSegmentSum}}]] [Op:__inference_train_function_10605]"
     ]
    }
   ],
   "source": [
    "main_model.compile(\"adam\", \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "reset_seeds()\n",
    "model_history = main_model.fit(\n",
    "    X_train_padded, \n",
    "    y_train, \n",
    "    epochs=30, \n",
    "    batch_size=64, \n",
    "    validation_data=(X_val_padded, y_val), \n",
    "    callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the training/validation accuracy and loss\n",
    "plot_graphs(model_history, \"accuracy\")\n",
    "plot_graphs(model_history, \"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the predicted target class: if pred > 0.5, then y_pred = 1; else, y_pred = 0\n",
    "y_pred = np.array([1 if pred > 0.5 else 0 for pred in main_model.predict(X_val_padded)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the validation accuracy\n",
    "validation_acc = sum(y_pred == y_val)/len(y_val)\n",
    "validation_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the confusion matrix\n",
    "confusion_matrix_df = pd.DataFrame(\n",
    "        confusion_matrix(y_true=y_val, y_pred=y_pred, labels=[1, 0]),\n",
    "        index=['True:pos', 'True:neg'], \n",
    "        columns=['Pred:pos', 'Pred:neg']\n",
    "    )\n",
    "confusion_matrix_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counts of positive and negative predictions\n",
    "pd.value_counts(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Save the trained classifier for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create a saved model folder `main_model`.\n",
    "# main_model.save('../full_experiments1/experiment_cardiovascular1/main_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main_model = keras.models.load_model('../full_experiments1/experiment_cardiovascular1/main_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Get the negative predictions from LSTM, for counterfactual explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get these instances of negative predictions\n",
    "X_pred_negative = X_val_padded[y_pred == 0]\n",
    "\n",
    "X_pred_negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pred_negative.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the index of negative predictions to find the original row with the diagnosis codes\n",
    "# np.where(y_pred == 0)\n",
    "pred_neg_data = validation_reordered.iloc[np.where(y_pred == 0)]\n",
    "\n",
    "# pred_neg_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert negatively predicted instances back to medical event form\n",
    "original_event_sequences = tokenizer.sequences_to_texts(X_pred_negative)\n",
    "\n",
    "# original_event_sequences[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_pos_data = validation_reordered.iloc[np.where(y_pred == 1)]\n",
    "\n",
    "pred_pos_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export as the desired input format of the DRG framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_datapath = data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(pred_neg_data[0]).to_csv(path_or_buf=out_datapath+'test_neg.txt', index=False, header=False, sep=' ', quoting=csv.QUOTE_NONE, escapechar=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(pred_neg_data['diag']).to_csv(path_or_buf=out_datapath+'test_neg_diag.txt', index=False, header=False, sep=' ', quoting=csv.QUOTE_NONE, escapechar=' ')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we need to use the inference script from the DRG framework (instructions in the README file) to modify those 110 negative predictions into positive instances. After that, we import the transformed results as below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 DeleteOnly model results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the transformed data\n",
    "results_path = '../full_experiments1/experiment_cardiovascular1/working_dir_cardiovascular1_delete1/'\n",
    "trans_results_delete = pd.read_csv(results_path+'preds', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_sequences = tokenizer.texts_to_sequences(trans_results_delete[0])\n",
    "\n",
    "X_test_padded = sequence.pad_sequences(X_test_sequences, maxlen=max_seq_length, padding='post')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 DeleteAndRetrieve model results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the transformed data\n",
    "delete_generate_results_path = '../full_experiments1/experiment_cardiovascular1/working_dir_cardiovascular1_delete_ret1/'\n",
    "delete_generate_results = pd.read_csv(delete_generate_results_path+'preds', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_sequences2 = tokenizer.texts_to_sequences(delete_generate_results[0])\n",
    "\n",
    "X_test_padded2 = sequence.pad_sequences(X_test_sequences2, maxlen=max_seq_length, padding='post')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Use 1NN baseline method to modify the negatively predicted instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit an unsupervised 1NN with all the positive seuquences, using 'hamming' distance\n",
    "nn_model = NearestNeighbors(1, metric='hamming')\n",
    "\n",
    "target_label = 1 \n",
    "X_target_label = X_train_padded[y_train == target_label] # training using the true labels\n",
    "\n",
    "nn_model.fit(X_target_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the closest neighbor (positive sequence) with the minimum 'hamming' distance, take it as a counterfactual\n",
    "closest = nn_model.kneighbors(X_pred_negative, return_distance=False)\n",
    "trans_results_nn = X_target_label[closest[:, 0]]\n",
    "\n",
    "trans_results_nn[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename 'trans_results_nn' to 'X_test_padded3' for result comparison\n",
    "X_test_padded3 = trans_results_nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Convert transformed results to event sequence format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert transformed sequences back to the form of original event sequences\n",
    "trans_event_sequences1 = tokenizer.sequences_to_texts(X_test_padded)\n",
    "trans_event_sequences2 = tokenizer.sequences_to_texts(X_test_padded2)\n",
    "trans_event_sequences3 = tokenizer.sequences_to_texts(X_test_padded3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Results comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Comparison between fraction of valid CFs (i.e. successfully generated counterfactuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the total counts \n",
    "test_size = X_pred_negative.shape[0]\n",
    "\n",
    "test_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "main_model.predict(X_test_padded).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fraction of valid transformed sequences, for DeleteOnly\n",
    "fraction_success = np.sum(main_model.predict(X_test_padded) > 0.5)/test_size\n",
    "print(round(fraction_success, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For DeleteAndRetrieve\n",
    "fraction_success2 = np.sum(main_model.predict(X_test_padded2) > 0.5)/test_size\n",
    "print(round(fraction_success2, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For 1NN modification\n",
    "fraction_success3 = np.sum(main_model.predict(X_test_padded3) > 0.5)/test_size\n",
    "print(round(fraction_success3, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Local outlier factor (LOF score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model for novelty detection (novelty=True), in order to get LOF score\n",
    "clf = LocalOutlierFactor(n_neighbors=20, novelty=True, contamination=0.1)\n",
    "# clf.fit(X_train_padded)\n",
    "clf.fit(X_target_label) # use the target class to train, instead of all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the LOF score for leave-out validation data\n",
    "y_pred_val = clf.predict(X_val_padded)\n",
    "\n",
    "n_error_val = y_pred_val[y_pred_val == -1].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_size = X_val_padded.shape[0]\n",
    "outlier_score_val = n_error_val/validation_size\n",
    "\n",
    "outlier_score_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the LOF score for DeleteOnly results\n",
    "y_pred_test = clf.predict(X_test_padded)\n",
    "n_error_test = y_pred_test[y_pred_test == -1].size\n",
    "\n",
    "outlier_score_test = n_error_test / test_size\n",
    "print(round(outlier_score_test, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the outlier score for DeleteAndRetrieve results\n",
    "y_pred_test2 = clf.predict(X_test_padded2)\n",
    "n_error_test2 = y_pred_test2[y_pred_test2 == -1].size\n",
    "\n",
    "outlier_score_test2 = n_error_test2 / test_size\n",
    "print(round(outlier_score_test2, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outlier score for 1NN baseline method\n",
    "y_pred_test3 = clf.predict(X_test_padded3)\n",
    "n_error_test3 = y_pred_test3[y_pred_test3 == -1].size\n",
    "\n",
    "outlier_score_test3 = n_error_test3 / test_size\n",
    "print(round(outlier_score_test3, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 BLEU-4 score (cumulative 4-gram BLEU score) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define smoothing function\n",
    "chencherry = SmoothingFunction()\n",
    "\n",
    "# Define a function to get pairwise BLEU scores\n",
    "def get_pairwise_bleu(original, transformed):\n",
    "    # 'weights=[0.25, 0.25, 0.25, 0.25]' means that calculate 4-gram BLEU scores cumulatively\n",
    "    results = [sentence_bleu(\n",
    "        references=[pair[0].split()], \n",
    "        hypothesis=pair[1].split(), \n",
    "        weights=[0.25, 0.25, 0.25, 0.25], \n",
    "        smoothing_function=chencherry.method1) \n",
    "        for pair in zip(original, transformed)]\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairwise_bleu = get_pairwise_bleu(original_event_sequences, trans_event_sequences1)\n",
    "avg_bleu = sum(pairwise_bleu)/test_size\n",
    "print(round(avg_bleu, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairwise_bleu2 = get_pairwise_bleu(original_event_sequences, trans_event_sequences2)\n",
    "avg_bleu2 = sum(pairwise_bleu2)/test_size\n",
    "print(round(avg_bleu2, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pairwise_bleu3 = get_pairwise_bleu(original_event_sequences, trans_event_sequences3)\n",
    "avg_bleu3 = sum(pairwise_bleu3)/test_size\n",
    "print(round(avg_bleu3, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Edit distance (Levenshtein)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_edit_distance(original, transformed):\n",
    "    edit_distance_pair = [editdistance.eval(o, t) for o, t in zip(original.tolist(), transformed.tolist())]\n",
    "    edit_score = np.mean(edit_distance_pair)\n",
    "    \n",
    "    return round(edit_score, 4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_edit_distance(X_test_padded, X_pred_negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_edit_distance(X_test_padded2, X_pred_negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_edit_distance(X_test_padded3, X_pred_negative)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update: Extract valid counterfactuals for qualitative evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_flags = main_model.predict(X_test_padded) > 0.5\n",
    "valid_flags2 = main_model.predict(X_test_padded2) > 0.5\n",
    "valid_flags3 = main_model.predict(X_test_padded3) > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_valid_idx = np.where((valid_flags == True) & (valid_flags2 == True) & (valid_flags3 == True), True, False)\n",
    "\n",
    "all_valid_idx.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_df = pd.DataFrame(original_event_sequences)\n",
    "transformed_df['all_valid'] = all_valid_idx\n",
    "transformed_df['count'] = transformed_df[0].apply(lambda x: len([event for event in x.split()]))\n",
    "\n",
    "transformed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_df['delete'] = trans_event_sequences1\n",
    "transformed_df['delete_retrieve'] =trans_event_sequences2\n",
    "transformed_df['nn'] = trans_event_sequences3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_idx = np.where((transformed_df['count'] >= 10) & (transformed_df['count'] <= 30) & (transformed_df['all_valid'] == True), True, False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_transformed_df = transformed_df[selected_idx.reshape(-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_transformed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_transformed_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_transformed_df.iloc[0]['nn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_transformed_df.to_csv(path_or_buf='valid_transformations.csv', \n",
    "                            index=True, header=True, sep=',')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}