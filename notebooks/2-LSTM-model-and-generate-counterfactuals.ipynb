{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.neighbors import NearestNeighbors, LocalOutlierFactor\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import random as python_random\n",
    "from keras import layers\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from keras import backend as K\n",
    "\n",
    "import pandas.io.sql as sqlio\n",
    "import psycopg2\n",
    "import getpass\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define MIMIC data path\n",
    "data_path = '../mimic_data/'\n",
    "\n",
    "# Load training data\n",
    "train_pos = pd.read_csv(data_path+'train_pos.txt', header=None)\n",
    "train_neg = pd.read_csv(data_path+'train_neg.txt', header=None)\n",
    "\n",
    "# Add target class label\n",
    "train_pos['survival'] = [1 for i in range(train_pos.shape[0])]\n",
    "train_neg['survival'] = [0 for i in range(train_neg.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pos.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concat into one data frame; and reorder it\n",
    "train = pd.concat([train_pos, train_neg]).reset_index()\n",
    "train_reordered = train.sample(frac=1, random_state=3)\n",
    "\n",
    "X_train, y_train = train_reordered[0], train_reordered['survival']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load validation data\n",
    "validation_pos = pd.read_csv(data_path+'validation_pos.txt', header=None)\n",
    "validation_neg = pd.read_csv(data_path+'validation_neg.txt', header=None)\n",
    "\n",
    "# Add target class\n",
    "validation_pos['survival'] = [1 for i in range(validation_pos.shape[0])]\n",
    "validation_neg['survival'] = [0 for i in range(validation_neg.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation = pd.concat([validation_pos, validation_neg]).reset_index()\n",
    "validation_reordered = validation.sample(frac=1, random_state=3)\n",
    "\n",
    "X_val, y_val = validation_reordered[0], validation_reordered['survival']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing\n",
    "\n",
    "#### 1.1 Conver all the events into sequence (token) ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the vocab size and max sequence lenght\n",
    "vocab_size = 1100 #(max vocab id=1024 in the training data)\n",
    "max_seq_length = 74 #(the maximum sequence length in training/testing data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a text tokenizer to convert events\n",
    "tokenizer = Tokenizer(num_words = vocab_size)\n",
    "tokenizer.fit_on_texts(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sequences = tokenizer.texts_to_sequences(X_train)\n",
    "X_val_sequences = tokenizer.texts_to_sequences(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before texts_to_sequences()\n",
    "print(f'Before texts_to_sequences():\\n {X_train.iloc[0]}\\n')\n",
    "\n",
    "# After texts_to_sequences()\n",
    "print(f'After texts_to_sequences():\\n {X_train_sequences[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Padding converted sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad X_train_sequences and X_val_sequences\n",
    "X_train_padded = sequence.pad_sequences(X_train_sequences, maxlen=max_seq_length, padding='post')\n",
    "X_val_padded = sequence.pad_sequences(X_val_sequences, maxlen=max_seq_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_padded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_padded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_padded[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Train the main LSTM model for survival prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For plotting the accuracy/loss of keras models\n",
    "def plot_graphs(history, string):\n",
    "    plt.plot(history.history[string])\n",
    "    plt.plot(history.history['val_'+string])\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(string)\n",
    "    plt.legend([string, 'val_'+string])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix the random seeds to get consistent models\n",
    "## ref: https://keras.io/getting_started/faq/#how-can-i-obtain-reproducible-results-using-keras-during-development\n",
    "seed_value = 3\n",
    "\n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "\n",
    "# The below is necessary for starting Numpy generated random numbers in a well-defined initial state.\n",
    "np.random.seed(seed_value)\n",
    "\n",
    "# The below is necessary for starting core Python generated random numbers in a well-defined state.\n",
    "python_random.seed(seed_value)\n",
    "\n",
    "# The below set_seed() will make random number generation\n",
    "tf.random.set_seed(seed_value)\n",
    "\n",
    "# configure a new global `tensorflow` session\n",
    "session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
    "tf.compat.v1.keras.backend.set_session(sess)\n",
    "\n",
    "def reset_seeds(seed_value=3):\n",
    "    os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "    np.random.seed(seed_value) \n",
    "    python_random.seed(seed_value)\n",
    "    tf.random.set_seed(seed_value)\n",
    "\n",
    "reset_seeds() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the early stopping criteria\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model structure\n",
    "# Input for variable-length sequences of integers\n",
    "inputs = keras.Input(shape=(None,), dtype=\"int32\")\n",
    "\n",
    "# Embed each integer in a 128-dimensional vector\n",
    "x = layers.Embedding(vocab_size, 128)(inputs)\n",
    "\n",
    "# Add 2 bidirectional LSTMs\n",
    "x = layers.Bidirectional(layers.LSTM(64, return_sequences=True))(x)\n",
    "x = layers.Bidirectional(layers.LSTM(64))(x)\n",
    "\n",
    "# Add a classifier\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "main_model = keras.Model(inputs, outputs)\n",
    "\n",
    "main_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_model.compile(\"adam\", \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "reset_seeds()\n",
    "model_history = main_model.fit(\n",
    "    X_train_padded, \n",
    "    y_train, \n",
    "    epochs=30, \n",
    "    batch_size=64, \n",
    "    validation_data=(X_val_padded, y_val), \n",
    "    callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the training/validation accuracy and loss\n",
    "plot_graphs(model_history, \"accuracy\")\n",
    "plot_graphs(model_history, \"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the predicted target class: if pred > 0.5, then y_pred = 1; else, y_pred = 0\n",
    "y_pred = np.array([1 if pred > 0.5 else 0 for pred in main_model.predict(X_val_padded)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the validation accuracy\n",
    "validation_acc = sum(y_pred == y_val)/len(y_val)\n",
    "validation_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the confusion matrix\n",
    "confusion_matrix_df = pd.DataFrame(\n",
    "        confusion_matrix(y_true=y_val, y_pred=y_pred, labels=[1, 0]),\n",
    "        index=['True:pos', 'True:neg'], \n",
    "        columns=['Pred:pos', 'Pred:neg']\n",
    "    )\n",
    "confusion_matrix_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counts of positive and negative predictions\n",
    "pd.value_counts(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Get the negative predictions from LSTM, for counterfactual explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get these instances of negative predictions\n",
    "X_pred_negative = X_val_padded[y_pred == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pred_negative.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Export as the desired input format of the DRG framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert negatively predicted instances back to medical event form\n",
    "original_event_sequences = tokenizer.sequences_to_texts(X_pred_negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_event_sequences[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(original_event_sequences).to_csv(path_or_buf='../mimic_data/test_neg.txt', index=False, header=False, sep=' ', quoting = csv.QUOTE_NONE, escapechar = ' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we need to use the inference script from the DRG framework (instructions in the README file) to modify those 110 negative predictions into positive instances. After that, we import the transformed results as below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 DeleteOnly model results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the transformed data\n",
    "results_path = '../pred_delete2/'\n",
    "trans_results_delete = pd.read_csv(results_path+'preds', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_sequences = tokenizer.texts_to_sequences(trans_results_delete[0])\n",
    "\n",
    "X_test_padded = sequence.pad_sequences(X_test_sequences, maxlen=max_seq_length, padding='post')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 DeleteAndRetrieve model results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the transformed data\n",
    "delete_generate_results_path = '../pred_delete_retrieve2/'\n",
    "delete_generate_results = pd.read_csv(delete_generate_results_path+'preds', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_sequences2 = tokenizer.texts_to_sequences(delete_generate_results[0])\n",
    "\n",
    "X_test_padded2 = sequence.pad_sequences(X_test_sequences2, maxlen=max_seq_length, padding='post')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Use 1NN baseline method to modify the negatively predicted instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit an unsupervised 1NN with all the positive seuquences, using 'hamming' distance\n",
    "nn_model = NearestNeighbors(1, metric='hamming')\n",
    "\n",
    "target_label = 1 \n",
    "X_target_label = X_train_padded[y_train == target_label]\n",
    "\n",
    "nn_model.fit(X_target_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the closest neighbor (positive sequence) with the minimum 'hamming' distance, take it as a counterfactual\n",
    "closest = nn_model.kneighbors(X_pred_negative, return_distance=False)\n",
    "trans_results_nn = X_target_label[closest[:, 0]]\n",
    "\n",
    "trans_results_nn[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename 'trans_results_nn' to 'X_test_padded3' for result comparison\n",
    "X_test_padded3 = trans_results_nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Convert transformed results to event sequence format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert transformed sequences back to the form of original event sequences\n",
    "trans_event_sequences1 = tokenizer.sequences_to_texts(X_test_padded)\n",
    "trans_event_sequences2 = tokenizer.sequences_to_texts(X_test_padded2)\n",
    "trans_event_sequences3 = tokenizer.sequences_to_texts(X_test_padded3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Results comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Comparison between fraction of valid CFs (i.e. successfully generated counterfactuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the total counts \n",
    "test_size = X_pred_negative.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fraction of valid transformed sequences, for DeleteOnly\n",
    "fraction_success = np.sum(main_model.predict(X_test_padded) > 0.5)/test_size\n",
    "print(round(fraction_success, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For DeleteAndRetrieve\n",
    "fraction_success2 = np.sum(main_model.predict(X_test_padded2) > 0.5)/test_size\n",
    "print(round(fraction_success2, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For 1NN modification\n",
    "fraction_success3 = np.sum(main_model.predict(X_test_padded3) > 0.5)/test_size\n",
    "print(round(fraction_success3, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Local outlier factor (LOF score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model for novelty detection (novelty=True), in order to get LOF score\n",
    "clf = LocalOutlierFactor(n_neighbors=20, novelty=True, contamination=0.1)\n",
    "clf.fit(X_train_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the LOF score for leave-out validation data\n",
    "y_pred_val = clf.predict(X_val_padded)\n",
    "\n",
    "n_error_val = y_pred_val[y_pred_val == -1].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_size = X_val_padded.shape[0]\n",
    "outlier_score_val = n_error_val/validation_size\n",
    "\n",
    "outlier_score_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the LOF score for DeleteOnly results\n",
    "y_pred_test = clf.predict(X_test_padded)\n",
    "n_error_test = y_pred_test[y_pred_test == -1].size\n",
    "\n",
    "outlier_score_test = n_error_test / test_size\n",
    "print(round(outlier_score_test, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the outlier score for DeleteAndRetrieve results\n",
    "y_pred_test2 = clf.predict(X_test_padded2)\n",
    "n_error_test2 = y_pred_test2[y_pred_test2 == -1].size\n",
    "\n",
    "outlier_score_test2 = n_error_test2 / test_size\n",
    "print(round(outlier_score_test2, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outlier score for 1NN baseline method\n",
    "y_pred_test3 = clf.predict(X_test_padded3)\n",
    "n_error_test3 = y_pred_test3[y_pred_test3 == -1].size\n",
    "\n",
    "outlier_score_test3 = n_error_test3 / test_size\n",
    "print(round(outlier_score_test3, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 BLEU-4 score (cumulative 4-gram BLEU score) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define smoothing function\n",
    "chencherry = SmoothingFunction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to get pairwise BLEU scores\n",
    "def get_pairwise_bleu(original, transformed):\n",
    "    # 'weights=[0.25, 0.25, 0.25, 0.25]' means that calculate 4-gram BLEU scores cumulatively\n",
    "    results = [sentence_bleu(\n",
    "        references=[pair[0].split()], \n",
    "        hypothesis=pair[1].split(), \n",
    "        weights=[0.25, 0.25, 0.25, 0.25], \n",
    "        smoothing_function=chencherry.method1) \n",
    "        for pair in zip(original, transformed)]\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairwise_bleu = get_pairwise_bleu(original_event_sequences, trans_event_sequences1)\n",
    "avg_bleu = sum(pairwise_bleu)/test_size\n",
    "print(round(avg_bleu, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairwise_bleu2 = get_pairwise_bleu(original_event_sequences, trans_event_sequences2)\n",
    "avg_bleu2 = sum(pairwise_bleu2)/test_size\n",
    "print(round(avg_bleu2, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pairwise_bleu3 = get_pairwise_bleu(original_event_sequences, trans_event_sequences3)\n",
    "avg_bleu3 = sum(pairwise_bleu3)/test_size\n",
    "print(round(avg_bleu3, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3.1 Plot histograms of individual BLEU-4 scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(16,4))     \n",
    "\n",
    "plt.sca(ax[0])\n",
    "plt.title('DeleteOnly, BLUE score')\n",
    "plt.hist(pairwise_bleu, density=True, bins=30)\n",
    "\n",
    "plt.sca(ax[1])\n",
    "plt.title('DeleteAndRetrieve, BLUE score')\n",
    "plt.hist(pairwise_bleu2, density=True, bins=30)\n",
    "\n",
    "plt.sca(ax[2])\n",
    "plt.title('1-NN, BLUE score')\n",
    "plt.hist(pairwise_bleu3, density=True, bins=30)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Plot histograms of event count differences (modification counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The counts of total, drug events and procedures, for the original sequences\n",
    "original_counts = pd.DataFrame(columns=['total', 'drug', 'procedure'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_counts_table(event_sequences):\n",
    "    temp_list = list()\n",
    "    for seq in event_sequences:\n",
    "        splitted = seq.split()\n",
    "        total = len(splitted)\n",
    "        # MetaVision ITEMID values are all above 220000. Since this data only contains data from MetaVision, it only contains ITEMID above 220000\n",
    "        drug = len([x for x in splitted if int(x)>=220000])\n",
    "        procedure = total - drug\n",
    "\n",
    "        temp_list.append({'total': total, 'drug': drug, 'procedure': procedure})\n",
    "    \n",
    "    return pd.DataFrame(temp_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original_counts = get_counts_table(original_event_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get count tables for all the tranformed results (generated counterfactuals)\n",
    "trans_counts1 = get_counts_table(trans_event_sequences1)\n",
    "trans_counts2 = get_counts_table(trans_event_sequences2)\n",
    "trans_counts3 = get_counts_table(trans_event_sequences3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Substract the original counts to get event modifications for total, drug events and procedures\n",
    "substracted1 = trans_counts1.subtract(df_original_counts)\n",
    "substracted2 = trans_counts2.subtract(df_original_counts)\n",
    "substracted3 = trans_counts3.subtract(df_original_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 3x3 subplots\n",
    "fig, ax = plt.subplots(nrows=3, ncols=3, figsize=(16,12))\n",
    "\n",
    "plt.sca(ax[0,0])\n",
    "plt.title('DeleteOnly, total difference')\n",
    "plt.hist(substracted1['total'], density=True, bins=30)\n",
    "\n",
    "plt.sca(ax[0,1])\n",
    "plt.title('DeleteOnly, drug event difference')\n",
    "plt.hist(substracted1['drug'], density=True, bins=30)\n",
    "\n",
    "plt.sca(ax[0,2])\n",
    "plt.title('DeleteOnly, procedure difference')\n",
    "plt.hist(substracted1['procedure'], density=True, bins=12)\n",
    "\n",
    "plt.sca(ax[1,0])\n",
    "plt.title('DeleteAndRetrieve, total difference')\n",
    "plt.hist(substracted2['total'], density=True, bins=30)\n",
    "\n",
    "plt.sca(ax[1,1])\n",
    "plt.title('DeleteAndRetrieve, drug event difference')\n",
    "plt.hist(substracted2['drug'], density=True, bins=30)\n",
    "\n",
    "plt.sca(ax[1,2])\n",
    "plt.title('DeleteAndRetrieve, procedure difference')\n",
    "plt.hist(substracted2['procedure'], density=True, bins=12)\n",
    "\n",
    "plt.sca(ax[2,0])\n",
    "plt.title('1-NN, total difference')\n",
    "plt.hist(substracted3['total'], density=True, bins=30)\n",
    "\n",
    "plt.sca(ax[2,1])\n",
    "plt.title('1-NN, drug event difference')\n",
    "plt.hist(substracted3['drug'], density=True, bins=30)\n",
    "\n",
    "plt.sca(ax[2,2])\n",
    "plt.title('1-NN, procedure difference')\n",
    "plt.hist(substracted3['procedure'], density=True, bins=12)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 Export example counterfactuals "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert id to original event name\n",
    "conn = psycopg2.connect(\n",
    "    database=\"mimic\", \n",
    "    user=$your_username$, \n",
    "    password=getpass.getpass(\"Enter postgres password\"), \n",
    "    host=\"127.0.0.1\", \n",
    "    port=\"5432\",\n",
    "    options=f'-c search_path=mimiciii')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a mapping from itemid to name (drug events)\n",
    "itemid_to_name = pd.read_sql(\n",
    "    \"\"\"\n",
    "    SELECT itemid, abbreviation, label\n",
    "    FROM d_items;\n",
    "    \"\"\", conn)\n",
    "\n",
    "itemid_to_name = itemid_to_name[itemid_to_name['itemid'] >= 220000]\n",
    "itemid_to_name.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get another mapping from procedure itemid to name \n",
    "itemid_to_name2 = pd.read_sql(\n",
    "    \"\"\"\n",
    "    SELECT icd9_code, short_title, long_title\n",
    "    FROM d_icd_procedures;\n",
    "    \"\"\", conn)\n",
    "\n",
    "itemid_to_name2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concate two itemid_to_name into one table\n",
    "itemid_to_name2 = itemid_to_name2.rename(columns={'icd9_code': 'itemid', 'short_title': 'abbreviation', 'long_title': 'label'})\n",
    "\n",
    "itemid_to_name_concat = pd.concat([itemid_to_name, itemid_to_name2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data type to be consistent when filtering, e.g. 'itemid_to_name_concat['itemid'] == 9671'\n",
    "itemid_to_name_concat['label'] = itemid_to_name_concat['label'].astype('str') \n",
    "itemid_to_name_concat['itemid'] = itemid_to_name_concat['itemid'].astype('int') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a method to convert event codes to original names\n",
    "def code_to_name(event_sequence):\n",
    "    code_sequence = [int(event) for event in event_sequence.split()]\n",
    "    \n",
    "    temp_list = list()\n",
    "    for code in code_sequence:\n",
    "        event_name = itemid_to_name_concat[itemid_to_name_concat['itemid'] == code]['label'].item()\n",
    "        temp_list.append(event_name)\n",
    "    \n",
    "    return temp_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the sample for example counterfactuals\n",
    "sample_id = 44"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_to_name(original_event_sequences[sample_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original_event_sequences[sample_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_to_name(trans_event_sequences1[sample_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trans_event_sequences1[sample_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_to_name(trans_event_sequences2[sample_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trans_event_sequences2[sample_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "code_to_name(trans_event_sequences3[sample_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trans_event_sequences3[sample_id]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
